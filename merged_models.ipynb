{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import os as os\n",
    "import skfuzzy as fuzz\n",
    "import random\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ar41_for_ulb_comp.csv', sep=\";\", parse_dates=True, index_col=\"timestamps_UTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['RS_E_InAirTemp_PC1', 'RS_E_InAirTemp_PC2', 'RS_E_OilPress_PC1',\n",
    "            'RS_E_OilPress_PC2', 'RS_E_RPM_PC1', 'RS_E_RPM_PC2', 'RS_E_WatTemp_PC1',\n",
    "            'RS_E_WatTemp_PC2', 'RS_T_OilTemp_PC1', 'RS_T_OilTemp_PC2', 'temperature',\n",
    "            'precipitation', 'windspeed_10m', 'sum_pollen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the selected features from the DataFrame\n",
    "X = data[features]\n",
    "# Standardize (robust) the data\n",
    "Robustscaler = RobustScaler() # Test with robust scaler\n",
    "X_Robustscaled = Robustscaler.fit_transform(X)\n",
    "\n",
    "# Standardize (standard) the data\n",
    "standardscaler = StandardScaler()\n",
    "X_Standardscaled = standardscaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5  # Adjust this value based on the Elbow curve\n",
    "kmeansStandard = KMeans(n_clusters=k, random_state=0)\n",
    "kmeansStandard.fit(X_Standardscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get distances from center\n",
    "distances = kmeansStandard.transform(X_Standardscaled)\n",
    "\n",
    "# Get distance from closest center\n",
    "min_distances = distances.min(axis=1)\n",
    "\n",
    "min_distances_series = pd.Series(min_distances)\n",
    "\n",
    "# Take 5% quantile as threshold\n",
    "threshold = min_distances_series.quantile(0.95)\n",
    "\n",
    "data['kmean'] = (min_distances > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of Fuzzy C-means\n",
    "n_clusters = 4\n",
    "m = 2\n",
    "error_threshold = 0.005\n",
    "data_T = X_Robustscaled.T\n",
    "\n",
    "# Execution of Fuzzy C-means\n",
    "cntr, u, _, _, _, _, fpc = fuzz.cluster.cmeans(\n",
    "    data_T, n_clusters, m, error=error_threshold, maxiter=1000, init=None, seed=3\n",
    ")\n",
    "fpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "membership_values = np.argmax(u, axis=0)\n",
    "cntr_T = cntr.T\n",
    "distances = np.linalg.norm(data_T - cntr_T[:, membership_values], axis=0)\n",
    "outlier_distance_threshold = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = data[distances > outlier_distance_threshold]\n",
    "data['fuzzy'] = (distances > outlier_distance_threshold).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolation forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [500],\n",
    "    \"contamination\": [\"auto\"],\n",
    "}\n",
    "\n",
    "# Choix aléatoire des paramètres\n",
    "params = {param: random.choice(values) for param, values in param_grid.items()}\n",
    "\n",
    "\n",
    "clf = IsolationForest(**params, n_jobs=-1, max_samples=\"auto\")\n",
    "\n",
    "start_time = time()\n",
    "result = clf.fit_predict(X_Robustscaled)\n",
    "end_time = time()\n",
    "print(f\"Prediction time : {round(end_time - start_time, 2)} s\")\n",
    "\n",
    "\n",
    "data[\"isolation_forest\"] = result\n",
    "\n",
    "data[\"isolation_forest\"] = data[\"isolation_forest\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in col isolation_forest, replace -1 with 0\n",
    "data['isolation_forest'] = data['isolation_forest'].replace(1, 0)\n",
    "data['isolation_forest'] = data['isolation_forest'].replace(-1, 1)\n",
    "\n",
    "# make a col \"combined\" with value 1 if 'isol' and 'fuzzy' are 1, 0 otherwise\n",
    "data['combined'] = (data[['isolation_forest', 'fuzzy', 'kmean']].sum(axis=1) >= 2).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('ar41_for_ulb_merged.csv', sep=';')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
